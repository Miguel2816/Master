{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresividad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expresividad de los perceptrones multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arranca el entrenamiento de [esta red neuronal](https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.42555&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false). ¿Qué se observa? ¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "Se observa una red neuronal con dos capas ocultas, la primera consta de 4 neuronas y la segunda de 2 neuronas. El modelo no converge, da un error prácticamente del 50% y esto se debe a que se está utilizando una función de activación linear cuando el problema en cuestión no es linearmente separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrige el problema y copia en la siguiente celda la URL con la solución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:**\n",
    "\n",
    "Para corregir el problema es necesario modificar la función de activación. En el siguiente ejemplo se usa ReLU y se puede ver como en este caso si que es capaz de separar los puntos correctamente:\n",
    "\n",
    "https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.42555&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puede resolverse (conseguir un resultado razonablemente bueno) el problema [XOR](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.05067&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) con una red neuronal simple, sin capas ocultas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** No es posible resolverlo sin capas ocultas, a no ser que se añada como feature la variable X1X2, lo cual si que permitiría resolver el problema sin capas ocultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Y con [una capa oculta](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=1&seed=0.05067&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)? ¿Cuántas unidades harán falta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** Con una capa oculta es capaz de resolverlo con las 3 funciones de activación, sigmoid, tangente hiperbólica y ReLU relativamente rápido y con un error muy bajo con un total de 4 unidades. Además, se ha comprobado que con 3 unidades solo se consigue un resultado aceptable si se usa como función de activación la tangente hiperbólica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Tienes alguna intuición sobre cuántas unidades por capa serían necesarias si se usasen [dos capas ocultas](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,1&seed=0.05067&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** Según la función de activación la combinación de unidades por capa oculta es diferente:\n",
    "\n",
    "* Tangente hiperbólica: con 3 de neuronas en la primera es capaz de resolverlo con cualquier número de unidades en la segunda, aunque parece que el mejor resultado se da con 3 neuronas. A pesar de añadir una segunda capa, 2 neuronas en la primera no son suficientes para resolver el problema.\n",
    "\n",
    "* ReLU: se comprobó que una capa eran necesarias 4 unidades, pero con 2 capas, se consigue un buen resultado con 3 unidades en la primera capa y al menos 2 en la segunda.\n",
    "\n",
    "* Sigmoid: al añadir la segunda capa no es capaz de resolver el problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobreajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobreajuste en perceptrones multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de las dos gaussianas se puede resolver fácilmente con un [perceptrón simple](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=&seed=0.55412&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false), puesto que es linealmente separable. ¿Qué pasa si se utiliza un perceptrón multicapa? Copia la URL con la configuración y describe lo que ocurre al entrenar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Respuesta:** Se ha utilizado un perceptrón multicapa con 6 capas ocultas y 8 unidades por capa. Se observa que el modelo es capaz de predecir el resultado, observando que ambos errores, tanto training como test son prácticamente 0, y las principales diferencias con el modelo de un perceptrón simple son el tiempo de ejecución por época, siendo menor en el de perceptrón simple debido a la simplicidad del mismo, obviamente el coste computacional también será mucho menor, y también el modelo de un perceptrón simple alcanza con mayor rápidez el mejor resultado posible. La URL es:\n",
    "\n",
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=8,8,8,8,8,8&seed=0.55412&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "\n",
    "En este caso no se observa sobreajuste ya que el error en test es prácticamente 0, pero el uso de redes neuronales con multitud de capas y unidades puede llegar a este problema. Para evitar este problema es recomendable utilizar la técnica del early stopping observando como varían los errores en training y validación según las iteraciones, y hacer uso de la regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa, regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usa clase [MLPRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) de Scikit-learn para resolver el problema de Boston Housing. Recuerda que:\n",
    "* Para estimar correctamente el error de test deberías hacer un particionado de los datos en train/test\n",
    "* Los MLPs, como todos los modelos que se entrenan con descenso por gradiente, son sensibles a la escala de las variables de entrada, por lo que hay que estandarizarlas (usa el pipeline y el transformador que vimos en el cuaderno 1)\n",
    "Prueba con distintos números y tamaños de las capas ocultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar eliminamos los warnings, y establecemos una semilla por lo comentado en los ejercicios de modelos lineales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Miguel Pérez'\n",
    "seed = sum(ord(s) for s in name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston, load_digits\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston, y_boston = load_boston(return_X_y=True)\n",
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(X_boston, y_boston, test_size=0.3, \n",
    "                                                                                random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera la pipeline que contiene la normalización de los datos y el modelo.\n",
    "También se genera un espacio de búsqueda con diferentes combinaciones de arquitecturas para la red neuronal así como el parámetro de regularización para ver cuál es la mejor combinación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('stds',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('predictor',\n",
       "                                        MLPRegressor(activation='relu',\n",
       "                                                     alpha=0.0001,\n",
       "                                                     batch_size='auto',\n",
       "                                                     beta_1=0.9, beta_2=0.999,\n",
       "                                                     early_stopping=False,\n",
       "                                                     epsilon=1e-08,\n",
       "                                                     hidden_layer_sizes=(100,),\n",
       "                                                     learning_rate='constant',\n",
       "                                                     learning_rate_init=0.001,\n",
       "                                                     max_...\n",
       "                                                     verbose=False,\n",
       "                                                     warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'predictor__alpha': [1e-05, 0.0001, 0.001],\n",
       "                         'predictor__hidden_layer_sizes': [[100], [100, 100],\n",
       "                                                           [100, 100, 100],\n",
       "                                                           [50], [50, 50],\n",
       "                                                           [50, 50, 50], [150],\n",
       "                                                           [100, 150],\n",
       "                                                           [100, 150, 100]],\n",
       "                         'predictor__max_iter': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpr = Pipeline([('stds', StandardScaler()), ('predictor', MLPRegressor())])\n",
    "search_space = {'predictor__hidden_layer_sizes': [[100], [100,100], [100,100,100],\n",
    "                                                  [50], [50,50], [50,50,50],\n",
    "                                                  [150], [100,150], [100,150,100]],\n",
    "                'predictor__alpha': [0.00001, 0.0001, 0.001],\n",
    "                'predictor__max_iter': [500]}\n",
    "estimator = GridSearchCV(mlpr, search_space, cv=5)\n",
    "estimator.fit(X_train_boston, y_train_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'predictor__alpha': 0.0001, 'predictor__hidden_layer_sizes': [100, 150, 100], 'predictor__max_iter': 500}\n",
      "Best score: 0.8250605137165105\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ' + str(estimator.best_params_))\n",
    "print('Best score: ' + str(estimator.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que la mejor arquitectura se consigue con tres capas de 100, 150 y 100 unidades cada una respectivamente y un parámetro de regularización igual a 0.0001.\n",
    "\n",
    "A continuación se van a generar los errores tanto para la parte de training como para la de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.144582459745545 MAE: 0.7279511121673974\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = estimator.predict(X_train_boston)\n",
    "\n",
    "mse = mean_squared_error(y_train_boston, y_pred_train)\n",
    "mae = mean_absolute_error(y_train_boston, y_pred_train)\n",
    "print(\"MSE: \" + str(mse) + \" MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 11.369359474881506 MAE: 2.2426693769731973\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = estimator.predict(X_test_boston)\n",
    "\n",
    "mse = mean_squared_error(y_test_boston, y_pred_test)\n",
    "mae = mean_absolute_error(y_test_boston, y_pred_test)\n",
    "print(\"MSE: \" + str(mse) + \" MAE: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los resultados en la parte de test son más elevados que los de training, algo esperable, pero siguen siendo valores bajos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de meta-parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los MLPs tienen un gran número de meta-parámetros que ajustar. Prueba una búsqueda de meta-parámetros automatizada ([GridSearchCV](scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) o [RandomizedSearchCV](scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)) para realizar una búsqueda sobre el parámetro de regularización alpha del MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repuesta:** Ya se ha hecho uso de la función GridSearch en el apartado anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa, clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usa la clase [MLPClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) con el problema [Digits](scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "X_train_digits, X_test_digits, y_train_digits, y_test_digits = train_test_split(X_digits, y_digits, test_size=0.3, \n",
    "                                                                                random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera la pipeline que contiene la normalización de los datos y el modelo.\n",
    "También se genera un espacio de búsqueda con diferentes combinaciones de arquitecturas para la red neuronal así como el parámetro de regularización para ver cuál es la mejor combinación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('stds',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('predictor',\n",
       "                                        MLPClassifier(activation='relu',\n",
       "                                                      alpha=0.0001,\n",
       "                                                      batch_size='auto',\n",
       "                                                      beta_1=0.9, beta_2=0.999,\n",
       "                                                      early_stopping=False,\n",
       "                                                      epsilon=1e-08,\n",
       "                                                      hidden_layer_sizes=(100,),\n",
       "                                                      learning_rate='constant',\n",
       "                                                      learning_rate_init=0.001,\n",
       "                                                      max...\n",
       "                                                      verbose=False,\n",
       "                                                      warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'predictor__alpha': [1e-05, 0.0001, 0.001],\n",
       "                         'predictor__hidden_layer_sizes': [[100], [100, 100],\n",
       "                                                           [100, 100, 100],\n",
       "                                                           [50], [50, 50],\n",
       "                                                           [50, 50, 50], [150],\n",
       "                                                           [100, 150],\n",
       "                                                           [100, 150, 100]],\n",
       "                         'predictor__max_iter': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpc = Pipeline([('stds', StandardScaler()), ('predictor', MLPClassifier())])\n",
    "search_space = {'predictor__hidden_layer_sizes': [[100], [100,100], [100,100,100],\n",
    "                                                  [50], [50,50], [50,50,50],\n",
    "                                                  [150], [100,150], [100,150,100]],\n",
    "                'predictor__alpha': [0.00001, 0.0001, 0.001],\n",
    "                'predictor__max_iter': [500]}\n",
    "estimator_mlpc = GridSearchCV(mlpc, search_space, cv=5)\n",
    "estimator_mlpc.fit(X_train_digits, y_train_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'predictor__alpha': 0.001, 'predictor__hidden_layer_sizes': [150], 'predictor__max_iter': 500}\n",
      "Best score: 0.9729589578195157\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ' + str(estimator_mlpc.best_params_))\n",
    "print('Best score: ' + str(estimator_mlpc.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el mejor modelo se consigue con una capa oculta de 150 unidades y un parámetro de regularización igual a 0.001.\n",
    "\n",
    "A continuación se generan los errores tanto para training como para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_train_digits = estimator_mlpc.predict(X_train_digits)\n",
    "print(accuracy_score(y_train_digits, y_pred_train_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796296296296296\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_digits = estimator_mlpc.predict(X_test_digits)\n",
    "print(accuracy_score(y_test_digits, y_pred_test_digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que para training se consigue predecir todo mientras que para test el resultado es menor, pero sigue siendo muy elevado, por lo que el modelo funciona bien, aunque puede ser mejorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
