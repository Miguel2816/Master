{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edd355c",
   "metadata": {},
   "source": [
    "# TFM M√°ster Data Science UAH 2020-2021\n",
    "\n",
    "### MIGUEL P√âREZ CARO\n",
    "\n",
    "Este notebook tiene como objetivo juntar todos los archivos individuales generados para la recogida de tweets y eliminar los duplicados qu epueda existir, de forma que se obtenga un set de datos final, sin duplicados y sin preprocesar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b3f65",
   "metadata": {},
   "source": [
    "Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9d695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e6b213",
   "metadata": {},
   "source": [
    "Establecer drectorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13999719",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = os.path.dirname(os.getcwd())\n",
    "mydir = os.path.join(directorio, 'data')\n",
    "os.chdir(mydir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f77ce",
   "metadata": {},
   "source": [
    "Obtener todos los archivos a partir de la extensi√≥n csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82183c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcda00e",
   "metadata": {},
   "source": [
    "Concatenar los archivos en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534e4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw_dup = pd.concat([pd.read_csv(f) for f in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bfd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(filenames):\n",
    "    df_raw_dup = pd.DataFrame()\n",
    "    for f in filenames:\n",
    "        if 'American' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['american'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'Delta' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['delta'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'Southwest' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['southwest'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'United' in f or 'united' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['united'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "    \n",
    "    return df_raw_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475a8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dup = concatenate(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e6f42",
   "metadata": {},
   "source": [
    "Comprobar el tama√±o del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7d58ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732023, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc74e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 732023 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              732023 non-null  int64  \n",
      " 1   created_at      732023 non-null  object \n",
      " 2   text            732023 non-null  object \n",
      " 3   retweet_count   732023 non-null  int64  \n",
      " 4   favorite_count  732023 non-null  int64  \n",
      " 5   southwest       168046 non-null  float64\n",
      " 6   american        194250 non-null  float64\n",
      " 7   united          180021 non-null  float64\n",
      " 8   delta           189706 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 55.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw_dup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494e0a9",
   "metadata": {},
   "source": [
    "Comprobar los tweets duplicados por id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1213d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165376\n"
     ]
    }
   ],
   "source": [
    "print(df_raw_dup['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edcacb",
   "metadata": {},
   "source": [
    "Estos duplicados se deben a la metodolog√≠a de extracci√≥n de datos, con 3 posibles escenarios:\n",
    "\n",
    "- Para la recogida de tweets de una aerol√≠nea, se usan dos formatos, por el username, y por el nombre de la aerol√≠nea. Es posible que un mismo tweet mencione la aerl√≠nea por su username y por su nombre, lo que har√≠a que existiese un duplicado.\n",
    "- Existe la posibilidad de que un mismo tweet mencione 2,3 o las 4 aerol√≠neas, por lo que ser√≠a recogido en cada set de datos correspondiente a cada aerol√≠nea.\n",
    "- Finalmente, tambi√©n puede suceder, debido a los tramos de tiempo de recogida, que un mismo tweet aparezca en dos set de datos que se hayan recogido en diferentes fechas.\n",
    "\n",
    "En el primer y en el √∫ltimo escenario, la eliminaci√≥n de todos los duplicados menos uno ser√≠a suficiente para arreglar el problema, pero en el segundo no, ya que aparecer√≠a solo 1 tweet correspondiente a una de las aerol√≠neas, pero no tendr√≠amos constancia del resto, por lo que hay que tenerlo en cuenta a la hora de tratar el dato. Para ello, en vez de una elimnaci√≥n de duplicados, se va a realizar un groupby por el id.\n",
    "\n",
    "En primer lugar observamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f78cd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>southwest</th>\n",
       "      <th>american</th>\n",
       "      <th>united</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1428307624454365191</td>\n",
       "      <td>2021-08-19 10:47:28</td>\n",
       "      <td>Mom claims Southwest Airlines flight attendant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1428307318656147462</td>\n",
       "      <td>2021-08-19 10:46:16</td>\n",
       "      <td>Southwest Airlines joins Sabre providing indus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1428306497667321858</td>\n",
       "      <td>2021-08-19 10:43:00</td>\n",
       "      <td>RT @TreStewart_: It‚Äôs a wild ride to be in the...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1428306147262402565</td>\n",
       "      <td>2021-08-19 10:41:36</td>\n",
       "      <td>RT @LiveandLetsFly: Southwest Airlines Delays ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1428303608810979331</td>\n",
       "      <td>2021-08-19 10:31:31</td>\n",
       "      <td>RT @garethicke: Every single one of these chil...</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1428307624454365191  2021-08-19 10:47:28   \n",
       "1  1428307318656147462  2021-08-19 10:46:16   \n",
       "2  1428306497667321858  2021-08-19 10:43:00   \n",
       "3  1428306147262402565  2021-08-19 10:41:36   \n",
       "4  1428303608810979331  2021-08-19 10:31:31   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  Mom claims Southwest Airlines flight attendant...              0   \n",
       "1  Southwest Airlines joins Sabre providing indus...              0   \n",
       "2  RT @TreStewart_: It‚Äôs a wild ride to be in the...             13   \n",
       "3  RT @LiveandLetsFly: Southwest Airlines Delays ...              1   \n",
       "4  RT @garethicke: Every single one of these chil...            460   \n",
       "\n",
       "   favorite_count  southwest  american  united  delta  \n",
       "0               0        1.0       NaN     NaN    NaN  \n",
       "1               0        1.0       NaN     NaN    NaN  \n",
       "2               0        1.0       NaN     NaN    NaN  \n",
       "3               0        1.0       NaN     NaN    NaN  \n",
       "4               0        1.0       NaN     NaN    NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_dup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101901fe",
   "metadata": {},
   "source": [
    "Rellenar los valores nulos con un 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf16c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dup['american'] = df_raw_dup['american'].fillna(0)\n",
    "df_raw_dup['delta'] = df_raw_dup['delta'].fillna(0)\n",
    "df_raw_dup['southwest'] = df_raw_dup['southwest'].fillna(0)\n",
    "df_raw_dup['united'] = df_raw_dup['united'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38228fdf",
   "metadata": {},
   "source": [
    "Se realiza la operaci√≥n de groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0779b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw_dup.groupby('id').agg({'created_at':'first', \n",
    "                           'text': 'first', \n",
    "                           'retweet_count':'max',\n",
    "                           'favorite_count': 'max',\n",
    "                           'southwest': 'max',\n",
    "                           'american': 'max',\n",
    "                           'united': 'max',\n",
    "                           'delta': 'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bf7a4",
   "metadata": {},
   "source": [
    "Se comprueba el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4317e743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566647, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305ad234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>southwest</th>\n",
       "      <th>american</th>\n",
       "      <th>united</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419550074791763968</td>\n",
       "      <td>2021-07-26 06:48:06</td>\n",
       "      <td>RT @JohnRLottJr: \"A United Airlines flight was...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419551078027202560</td>\n",
       "      <td>2021-07-26 06:52:05</td>\n",
       "      <td>@airvistara I have a booking from HYD to LAX w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419552199525425156</td>\n",
       "      <td>2021-07-26 06:56:33</td>\n",
       "      <td>US$263 - Cheap flights to West Palm Beach from...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419553072699920385</td>\n",
       "      <td>2021-07-26 07:00:01</td>\n",
       "      <td>üîÅ #ICYMI | The Bureau d‚ÄôEnqu√™tes et Analyses (...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419555506251837440</td>\n",
       "      <td>2021-07-26 07:09:41</td>\n",
       "      <td>United Airlines evacuates plane ready for take...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1419550074791763968  2021-07-26 06:48:06   \n",
       "1  1419551078027202560  2021-07-26 06:52:05   \n",
       "2  1419552199525425156  2021-07-26 06:56:33   \n",
       "3  1419553072699920385  2021-07-26 07:00:01   \n",
       "4  1419555506251837440  2021-07-26 07:09:41   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  RT @JohnRLottJr: \"A United Airlines flight was...              4   \n",
       "1  @airvistara I have a booking from HYD to LAX w...              0   \n",
       "2  US$263 - Cheap flights to West Palm Beach from...              0   \n",
       "3  üîÅ #ICYMI | The Bureau d‚ÄôEnqu√™tes et Analyses (...              0   \n",
       "4  United Airlines evacuates plane ready for take...              0   \n",
       "\n",
       "   favorite_count  southwest  american  united  delta  \n",
       "0               0        0.0       0.0     1.0    0.0  \n",
       "1               0        0.0       0.0     1.0    0.0  \n",
       "2               0        0.0       0.0     1.0    0.0  \n",
       "3               1        0.0       0.0     1.0    0.0  \n",
       "4               0        0.0       0.0     1.0    0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78468e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd592c",
   "metadata": {},
   "source": [
    "Parece que ya se ha obtenido un dataset sin duplicados, por lo que se procede a su almacenamiento.\n",
    "\n",
    "Cabe destacar que el objetivo de este notebook es √∫nicamente el de juntar los set de datos y guardarlos en un √∫nico dataset, por lo que a√∫n queda realizar una parte del preprocesado del dato, que incluso incluir√° tratamiento de duplicados, ya que en este caso solo se ha tenido en cuenta el tweet id, es decir, el identificador de cada tweet, pero puede haber muchos tweets cuyo texto sea igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5091b",
   "metadata": {},
   "source": [
    "Guardar el dataset en sin preprocesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84255f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_raw.csv\", sep = ',', index=False, \n",
    "              columns = ['id','created_at','text','retweet_count','favorite_count', 'southwest', \n",
    "                         'american', 'united', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a73e3",
   "metadata": {},
   "source": [
    "### Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef74f5",
   "metadata": {},
   "source": [
    "* Glob library documentation: https://docs.python.org/3/library/glob.html\n",
    "* OS library documentation: https://docs.python.org/3/library/os.path.html\n",
    "* Post: https://www.freecodecamp.org/news/how-to-combine-multiple-csv-files-with-8-lines-of-code-265183e0854/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
