{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8edd355c",
   "metadata": {},
   "source": [
    "# TFM Máster Data Science UAH 2020-2021\n",
    "\n",
    "### MIGUEL PÉREZ CARO\n",
    "\n",
    "Este notebook tiene como objetivo juntar todos los archivos individuales generados para la recogida de tweets y eliminar los duplicados qu epueda existir, de forma que se obtenga un set de datos final, sin duplicados y sin preprocesar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b3f65",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9d695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e6b213",
   "metadata": {},
   "source": [
    "Establecer drectorio de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13999719",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = os.path.dirname(os.getcwd())\n",
    "mydir = os.path.join(directorio, 'data')\n",
    "os.chdir(mydir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f77ce",
   "metadata": {},
   "source": [
    "Obtener todos los archivos a partir de la extensión csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82183c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcda00e",
   "metadata": {},
   "source": [
    "Concatenar los archivos en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534e4ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw_dup = pd.concat([pd.read_csv(f) for f in all_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bfd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(filenames):\n",
    "    df_raw_dup = pd.DataFrame()\n",
    "    for f in filenames:\n",
    "        if 'American' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['american'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'Delta' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['delta'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'Southwest' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['southwest'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "        \n",
    "        if 'United' in f or 'united' in f:\n",
    "            df = pd.read_csv(f)\n",
    "            df['united'] = 1\n",
    "            df_raw_dup = pd.concat([df_raw_dup, df])\n",
    "    \n",
    "    return df_raw_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475a8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dup = concatenate(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e6f42",
   "metadata": {},
   "source": [
    "Comprobar el tamaño del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a7d58ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732023, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_dup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc74e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 732023 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   id              732023 non-null  int64  \n",
      " 1   created_at      732023 non-null  object \n",
      " 2   text            732023 non-null  object \n",
      " 3   retweet_count   732023 non-null  int64  \n",
      " 4   favorite_count  732023 non-null  int64  \n",
      " 5   southwest       168046 non-null  float64\n",
      " 6   american        194250 non-null  float64\n",
      " 7   united          180021 non-null  float64\n",
      " 8   delta           189706 non-null  float64\n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 55.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw_dup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494e0a9",
   "metadata": {},
   "source": [
    "Comprobar los tweets duplicados por id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f1213d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165376\n"
     ]
    }
   ],
   "source": [
    "print(df_raw_dup['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edcacb",
   "metadata": {},
   "source": [
    "Estos duplicados se deben a la metodología de extracción de datos, con 3 posibles escenarios:\n",
    "\n",
    "- Para la recogida de tweets de una aerolínea, se usan dos formatos, por el username, y por el nombre de la aerolínea. Es posible que un mismo tweet mencione la aerlínea por su username y por su nombre, lo que haría que existiese un duplicado.\n",
    "- Existe la posibilidad de que un mismo tweet mencione 2,3 o las 4 aerolíneas, por lo que sería recogido en cada set de datos correspondiente a cada aerolínea.\n",
    "- Finalmente, también puede suceder, debido a los tramos de tiempo de recogida, que un mismo tweet aparezca en dos set de datos que se hayan recogido en diferentes fechas.\n",
    "\n",
    "En el primer y en el último escenario, la eliminación de todos los duplicados menos uno sería suficiente para arreglar el problema, pero en el segundo no, ya que aparecería solo 1 tweet correspondiente a una de las aerolíneas, pero no tendríamos constancia del resto, por lo que hay que tenerlo en cuenta a la hora de tratar el dato. Para ello, en vez de una elimnación de duplicados, se va a realizar un groupby por el id.\n",
    "\n",
    "En primer lugar observamos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f78cd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>southwest</th>\n",
       "      <th>american</th>\n",
       "      <th>united</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1428307624454365191</td>\n",
       "      <td>2021-08-19 10:47:28</td>\n",
       "      <td>Mom claims Southwest Airlines flight attendant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1428307318656147462</td>\n",
       "      <td>2021-08-19 10:46:16</td>\n",
       "      <td>Southwest Airlines joins Sabre providing indus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1428306497667321858</td>\n",
       "      <td>2021-08-19 10:43:00</td>\n",
       "      <td>RT @TreStewart_: It’s a wild ride to be in the...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1428306147262402565</td>\n",
       "      <td>2021-08-19 10:41:36</td>\n",
       "      <td>RT @LiveandLetsFly: Southwest Airlines Delays ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1428303608810979331</td>\n",
       "      <td>2021-08-19 10:31:31</td>\n",
       "      <td>RT @garethicke: Every single one of these chil...</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1428307624454365191  2021-08-19 10:47:28   \n",
       "1  1428307318656147462  2021-08-19 10:46:16   \n",
       "2  1428306497667321858  2021-08-19 10:43:00   \n",
       "3  1428306147262402565  2021-08-19 10:41:36   \n",
       "4  1428303608810979331  2021-08-19 10:31:31   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  Mom claims Southwest Airlines flight attendant...              0   \n",
       "1  Southwest Airlines joins Sabre providing indus...              0   \n",
       "2  RT @TreStewart_: It’s a wild ride to be in the...             13   \n",
       "3  RT @LiveandLetsFly: Southwest Airlines Delays ...              1   \n",
       "4  RT @garethicke: Every single one of these chil...            460   \n",
       "\n",
       "   favorite_count  southwest  american  united  delta  \n",
       "0               0        1.0       NaN     NaN    NaN  \n",
       "1               0        1.0       NaN     NaN    NaN  \n",
       "2               0        1.0       NaN     NaN    NaN  \n",
       "3               0        1.0       NaN     NaN    NaN  \n",
       "4               0        1.0       NaN     NaN    NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_dup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101901fe",
   "metadata": {},
   "source": [
    "Rellenar los valores nulos con un 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf16c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dup['american'] = df_raw_dup['american'].fillna(0)\n",
    "df_raw_dup['delta'] = df_raw_dup['delta'].fillna(0)\n",
    "df_raw_dup['southwest'] = df_raw_dup['southwest'].fillna(0)\n",
    "df_raw_dup['united'] = df_raw_dup['united'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38228fdf",
   "metadata": {},
   "source": [
    "Se realiza la operación de groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0779b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw_dup.groupby('id').agg({'created_at':'first', \n",
    "                           'text': 'first', \n",
    "                           'retweet_count':'max',\n",
    "                           'favorite_count': 'max',\n",
    "                           'southwest': 'max',\n",
    "                           'american': 'max',\n",
    "                           'united': 'max',\n",
    "                           'delta': 'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bf7a4",
   "metadata": {},
   "source": [
    "Se comprueba el resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4317e743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566647, 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305ad234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>southwest</th>\n",
       "      <th>american</th>\n",
       "      <th>united</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1419550074791763968</td>\n",
       "      <td>2021-07-26 06:48:06</td>\n",
       "      <td>RT @JohnRLottJr: \"A United Airlines flight was...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419551078027202560</td>\n",
       "      <td>2021-07-26 06:52:05</td>\n",
       "      <td>@airvistara I have a booking from HYD to LAX w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1419552199525425156</td>\n",
       "      <td>2021-07-26 06:56:33</td>\n",
       "      <td>US$263 - Cheap flights to West Palm Beach from...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1419553072699920385</td>\n",
       "      <td>2021-07-26 07:00:01</td>\n",
       "      <td>🔁 #ICYMI | The Bureau d’Enquêtes et Analyses (...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1419555506251837440</td>\n",
       "      <td>2021-07-26 07:09:41</td>\n",
       "      <td>United Airlines evacuates plane ready for take...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1419550074791763968  2021-07-26 06:48:06   \n",
       "1  1419551078027202560  2021-07-26 06:52:05   \n",
       "2  1419552199525425156  2021-07-26 06:56:33   \n",
       "3  1419553072699920385  2021-07-26 07:00:01   \n",
       "4  1419555506251837440  2021-07-26 07:09:41   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  RT @JohnRLottJr: \"A United Airlines flight was...              4   \n",
       "1  @airvistara I have a booking from HYD to LAX w...              0   \n",
       "2  US$263 - Cheap flights to West Palm Beach from...              0   \n",
       "3  🔁 #ICYMI | The Bureau d’Enquêtes et Analyses (...              0   \n",
       "4  United Airlines evacuates plane ready for take...              0   \n",
       "\n",
       "   favorite_count  southwest  american  united  delta  \n",
       "0               0        0.0       0.0     1.0    0.0  \n",
       "1               0        0.0       0.0     1.0    0.0  \n",
       "2               0        0.0       0.0     1.0    0.0  \n",
       "3               1        0.0       0.0     1.0    0.0  \n",
       "4               0        0.0       0.0     1.0    0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78468e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd592c",
   "metadata": {},
   "source": [
    "Parece que ya se ha obtenido un dataset sin duplicados, por lo que se procede a su almacenamiento.\n",
    "\n",
    "Cabe destacar que el objetivo de este notebook es únicamente el de juntar los set de datos y guardarlos en un único dataset, por lo que aún queda realizar una parte del preprocesado del dato, que incluso incluirá tratamiento de duplicados, ya que en este caso solo se ha tenido en cuenta el tweet id, es decir, el identificador de cada tweet, pero puede haber muchos tweets cuyo texto sea igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5091b",
   "metadata": {},
   "source": [
    "Guardar el dataset en sin preprocesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84255f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_raw.csv\", sep = ',', index=False, \n",
    "              columns = ['id','created_at','text','retweet_count','favorite_count', 'southwest', \n",
    "                         'american', 'united', 'delta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a73e3",
   "metadata": {},
   "source": [
    "### Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef74f5",
   "metadata": {},
   "source": [
    "* Glob library documentation: https://docs.python.org/3/library/glob.html\n",
    "* OS library documentation: https://docs.python.org/3/library/os.path.html\n",
    "* Post: https://www.freecodecamp.org/news/how-to-combine-multiple-csv-files-with-8-lines-of-code-265183e0854/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
